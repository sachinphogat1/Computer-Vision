{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CVProject2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "1Gc_nYwSK4tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f844f41-5d3d-49d5-b53b-09a97ff7ca69"
      },
      "execution_count": 567,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 568,
      "metadata": {
        "id": "lgxNreACHxJu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.layers import Concatenate,MaxPooling2D, Conv2D, Input, Dense, RepeatVector, Reshape, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)   # suppress scientific notation\n"
      ],
      "metadata": {
        "id": "KCr9-5pEH9L0"
      },
      "execution_count": 569,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, label_train), (x_test, label_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "7kyAeu-9IAbg"
      },
      "execution_count": 570,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_new = x_train[:4000]\n",
        "label_train_new = label_train[:4000]\n",
        "x_val_new = x_train[4000:5000]\n",
        "label_val_new = label_train[4000:5000]\n",
        "x_test_new = x_test[:1000]\n",
        "label_test_new = label_test[:1000]\n"
      ],
      "metadata": {
        "id": "8gkL_B6yIuAL"
      },
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TZ1jJgZKZDd",
        "outputId": "9fd6b6f8-ebe1-44e4-f8a9-70512c63213a"
      },
      "execution_count": 572,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 572
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we have to normalize the values of the pixels, so we will able to train neural networks with the ease"
      ],
      "metadata": {
        "id": "JH8qBlwCLkyE"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_train_new = label_train_new.astype('float32')\n",
        "# label_test = label_test.astype('float32')\n",
        "# label_val = label_val.astype('float32')\n",
        "x_train, x_test, x_val = x_train / 255.0, x_test / 255.0, x_val_new/255.0\n",
        "print(x_val.size)"
      ],
      "metadata": {
        "id": "S-ALWCOAL7mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2d30a8-b36e-4b8a-db97-6a93a1e368ae"
      },
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------\n",
        "# Save an image to a file\n",
        "#-----------\n",
        "# cv2.imwrite(\"x_train_0.png\", x_train[0])\n",
        "\n",
        "#make output directory\n",
        "os.system('mkdir output')\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "\tcv2.imwrite(\"output/train_{}.png\".format(i), 255*x_train[i])\n",
        "\tcv2.imwrite(\"output/test_{}.png\".format(i), 255*x_test[i])\n",
        "\n",
        "for i in range(5):\n",
        "\tcv2.imwrite(\"output/validation_{}.png\".format(i), 255*x_val[i])"
      ],
      "metadata": {
        "id": "1JGxjKjgL8Oe"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = x_train_new.shape[0]\n",
        "num_test  = x_test_new.shape[0]\n",
        "num_validation = x_val_new.shape[0]\n",
        "\n",
        "print(num_train, num_test, num_validation)"
      ],
      "metadata": {
        "id": "i5xrIBPVM8bS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84985724-81eb-474c-80b2-aa756cbc30b0"
      },
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 1000 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the training\n",
        "y_train = np.zeros([num_train, 10])\n",
        "for i in range(num_train):\n",
        "  y_train[i, label_train_new[i]] = 1\n",
        "\n",
        "# One-hot encode the testing\n",
        "y_test  = np.zeros([num_test, 10])\n",
        "for i in range(num_test):\n",
        "\ty_test[i, label_test[i]] = 1\n",
        "\n",
        "# One-hot encode the validation\n",
        "y_val = np.zeros([num_validation, 10])\n",
        "for i in range(num_validation):\n",
        "  y_val[i, label_val_new[i]] = 1"
      ],
      "metadata": {
        "id": "1OVrh0lR82iX"
      },
      "execution_count": 577,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(label_train_new[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moyQwjgaydsB",
        "outputId": "73d5f8a5-9170-420e-e385-16781df234db"
      },
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 10)\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_train, num_test, num_validation) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiS0EF2sPDI0",
        "outputId": "a7ff93d5-4fc6-422e-af1d-b15310389c84"
      },
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 1000 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape[0], x_train.shape[1], x_train.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOo5c_9pPGqX",
        "outputId": "b30e2a91-17a6-4c9b-e8b8-6b59fde3d530"
      },
      "execution_count": 580,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 28 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape into 28 x 28 shape\n",
        "x_train_new = np.reshape(x_train_new, (-1, x_train_new.shape[1] * x_train_new.shape[2]))\n",
        "x_test_new = np.reshape(x_test_new, (-1, x_test_new.shape[1] * x_test_new.shape[2]))\n",
        "x_val_new = np.reshape(x_val_new, (-1, x_val.shape[1] * x_val.shape[2]))"
      ],
      "metadata": {
        "id": "zphcA0dRQuoF"
      },
      "execution_count": 581,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_new.shape, x_test_new.shape, x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuRBGpQQEVPJ",
        "outputId": "f2858082-1e20-42c5-8a18-6fb747e63067"
      },
      "execution_count": 582,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 784) (1000, 784) (1000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create ResNet5 model"
      ],
      "metadata": {
        "id": "1YXyrlQvTM85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_filters = 2"
      ],
      "metadata": {
        "id": "9iPqKZYiRKcp"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=x_train_new.shape[1] , name=\"input_1\")\n",
        "repeat = RepeatVector(2, name=\"repeat_vector_1\")(inputs)\n",
        "print(inputs.shape)\n",
        "reshape = Reshape((28, 28, 2), name=\"reshape_1\")(repeat)\n"
      ],
      "metadata": {
        "id": "yoy3ilzjTBLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac2cf87-71b1-4828-f4bf-658d4f089e79"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d -> reshape_1[0][0]\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters, activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d\")(reshape)\n",
        "\n",
        "print(t.shape)"
      ],
      "metadata": {
        "id": "8fsMcp0FoSTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802bc0a7-91ff-4cfa-a55e-951e6d805398"
      },
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 28, 28, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_1 -> conv2d[0][0]\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=num_filters,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_1\")(t)\n",
        "print(t.shape)\n",
        "              "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU2G2egqNmOu",
        "outputId": "8f864309-d3f4-416c-91ce-af0c9e005b9f"
      },
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 28, 28, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate -> reshape_1[0][0], conv2d_1[0][0]\n",
        "t = Concatenate(name=\"concatenate\")([reshape, t])\n",
        "\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcK4t9VNN-cK",
        "outputId": "2a1493b4-f6fe-48ad-969e-886822ee0671"
      },
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 28, 28, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_pooling2d -> concatenate[0][0]\n",
        "t = MaxPooling2D(2,2)(t)\n",
        "MP_2D = t\n",
        "print(MP_2D.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brsVwGNRUY8P",
        "outputId": "f869ab66-a8f8-4d53-8f1b-9637577f09b0"
      },
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 14, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ##reshape = Reshape((28, 28, 2), name=\"reshape_2\")(repeat) "
      ],
      "metadata": {
        "id": "oXtqvzelocSA"
      },
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_2 -> max_pooling2d Line 8\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=4,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_2\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrl2T3DWfrW",
        "outputId": "fbdbcb45-0de1-4423-cb86-a2ed723c0649"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 14, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_3 -> conv2d_2 Line 9\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=4,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_3\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtvWmV0W8Y1",
        "outputId": "a166dba2-3935-4de3-b8d1-9ef3f9c9236d"
      },
      "execution_count": 591,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 14, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate_1 -> max_pooling2d, conv2d_3 Line 10\n",
        "\n",
        "t = Concatenate(name=\"concatenate_1\")([MP_2D, t])\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIZdn1A2XUry",
        "outputId": "3953d415-3ea5-4300-9cf7-dfe0f5d0034a"
      },
      "execution_count": 592,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 14, 14, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_pooling2d_1 -> concatenate_1 Line 11\n",
        "\n",
        "t = MaxPooling2D(2,2)(t)\n",
        "MP_2D_1 = t\n",
        "print(MP_2D_1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOyQxiuNaNun",
        "outputId": "cf4ca66b-d7bd-42b9-9bbf-c2f0e5ba2578"
      },
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_4 -> max_pooling2d_1 Line 12\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=8,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_4\")(MP_2D_1)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALrn1oPTbCvE",
        "outputId": "3415a9fd-55bc-4961-a8af-bb65c1facbe5"
      },
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_5 -> conv2d_4 Line 13\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=8,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_5\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG3Qd32lcLyM",
        "outputId": "ecd3878b-c08b-445a-b709-840d1b03aa57"
      },
      "execution_count": 595,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate_2 -> max_pooling2d_1, conv2d_5 Line 14\n",
        "\n",
        "t = Concatenate(name=\"concatenate_2\")([MP_2D_1, t])\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFkXw-B4cZsv",
        "outputId": "de9dff92-6a94-48dd-aa98-495b53053003"
      },
      "execution_count": 596,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_pooling2d_2 -> concatenate_2 Line 15\n",
        "\n",
        "t = MaxPooling2D(2,2)(t)\n",
        "MP_2D_2 = t\n",
        "print(MP_2D_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3HK39RuciZi",
        "outputId": "a996daf3-3404-442a-ca33-97de098347fc"
      },
      "execution_count": 597,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 3, 3, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_6 -> MP_2D_2 Line 16\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=16,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_6\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hEdVcdc1LJ",
        "outputId": "feb0cbea-13fd-426a-9be8-161850a997e1"
      },
      "execution_count": 598,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 3, 3, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_7 -> conv_2d_6 Line 17\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=16,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_7\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93XGfDgtdPmu",
        "outputId": "3235e228-2588-4e8a-ca52-027ac065d852"
      },
      "execution_count": 599,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 3, 3, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate_3 -> max_pooling2d_2, conv2d_7 Line 18\n",
        "\n",
        "t = Concatenate(name=\"concatenate_3\")([MP_2D_2, t])\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH3POLfEdmQs",
        "outputId": "4cb95176-6bca-4a69-e692-c12c2b954ff0"
      },
      "execution_count": 600,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 3, 3, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_pooling2d_3 -> concatenate_3 Line 19\n",
        "\n",
        "t = MaxPooling2D(2,2)(t)\n",
        "MP_2D_3 = t\n",
        "print(MP_2D_3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3cAEznKd1vB",
        "outputId": "22c1c590-b56a-4d25-a0b7-cb951f070a13"
      },
      "execution_count": 601,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1, 1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_8 -> max_pooling_2d_3 Line 20\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=32,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_8\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_P1-eMEeMsh",
        "outputId": "251c22c8-d14c-405a-ca74-3e80797af90d"
      },
      "execution_count": 602,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1, 1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conv2d_9 -> conv2d_8 Line 21\n",
        "t = Conv2D(kernel_size=3,\n",
        "               strides=1,\n",
        "               filters=32,\n",
        "           activation='relu',\n",
        "               padding=\"same\",  name=\"conv2d_9\")(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9L1xzf0esff",
        "outputId": "8390d75c-93bf-42f7-bef9-e4d081d24c24"
      },
      "execution_count": 603,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1, 1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concatenate_4 -> max_pooling2d_3, conv2d_9\n",
        "\n",
        "# t = Concatenate(name=\"concatenate_4\")([MP_2D_3, t])"
      ],
      "metadata": {
        "id": "J7K9q4WYkHvc"
      },
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flatten -> conv2d_9\n",
        "\n",
        "t = Flatten()(t)\n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbVahnKwfDZU",
        "outputId": "6d73afc2-b8dd-4268-91f3-2d8e8ac23305"
      },
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dense -> flatten\n",
        "\n",
        "t = Dense(20, activation='relu')(t) \n",
        "print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaxmIS9hgNQz",
        "outputId": "338ef852-1e77-4b41-d0f2-74bf89598e81"
      },
      "execution_count": 606,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dense_1 -> dense\n",
        "\n",
        "output = Dense(10, activation='softmax')(t) \n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Ym7QWtgSG1",
        "outputId": "10bf5fe5-d0c8-48f5-bee3-eb07c62567d1"
      },
      "execution_count": 607,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_27/Softmax:0', description=\"created by layer 'dense_27'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKxPRQ6EgdiK",
        "outputId": "e231dde9-3ce8-4d11-ed3b-c1f36044949a"
      },
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 784)]        0           []                               \n",
            "                                                                                                  \n",
            " repeat_vector_1 (RepeatVector)  (None, 2, 784)      0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 28, 28, 2)    0           ['repeat_vector_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 28, 28, 2)    38          ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 28, 28, 2)    38          ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 4)    0           ['reshape_1[0][0]',              \n",
            "                                                                  'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_52 (MaxPooling2D  (None, 14, 14, 4)   0           ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 14, 14, 4)    148         ['max_pooling2d_52[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 14, 14, 4)    148         ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 14, 14, 8)    0           ['max_pooling2d_52[0][0]',       \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_53 (MaxPooling2D  (None, 7, 7, 8)     0           ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 7, 7, 8)      584         ['max_pooling2d_53[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, 7, 8)      584         ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 7, 7, 16)     0           ['max_pooling2d_53[0][0]',       \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_54 (MaxPooling2D  (None, 3, 3, 16)    0           ['concatenate_2[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 3, 3, 16)     2320        ['max_pooling2d_54[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 3, 3, 16)     2320        ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 3, 3, 32)     0           ['max_pooling2d_54[0][0]',       \n",
            "                                                                  'conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_55 (MaxPooling2D  (None, 1, 1, 32)    0           ['concatenate_3[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 1, 1, 32)     9248        ['max_pooling2d_55[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 1, 1, 32)     9248        ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 32)           0           ['conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 20)           660         ['flatten_13[0][0]']             \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 10)           210         ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,546\n",
            "Trainable params: 25,546\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################################################################################################"
      ],
      "metadata": {
        "id": "uy_fMshOeoY0"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model summary in text file\n",
        "with open('output/modelsummary.txt', 'w') as f:\n",
        "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "#make output directory\n",
        "#os.system('mkdir output')\n",
        "\n",
        "\n",
        "#Now do the training\n",
        "from statistics import mean\n",
        "import math\n",
        "# def loss(y, y_hat):\n",
        "#     loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
        "#     return loss\n",
        "\n",
        "# loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss=loss_fn,\n",
        "#               metrics=['accuracy'])\n",
        "# md = model.fit(x_train_new, y_train, epochs=10)\n",
        "# metrics = model.evaluate(x_test_new,  y_test, verbose=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "num_batches = num_train/batch_size\n",
        "\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val_new, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_new, y_test))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "# train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "epoch_loss_train = []\n",
        "epoch_loss_test = []\n",
        "epoch_loss_val = []\n",
        "\n",
        "epoch_acc_train = []\n",
        "epoch_acc_test = []\n",
        "epoch_acc_val = []\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "\n",
        "    print(\"\\n\\n****************** epoch - {} ******************\\n\".format(epoch+1))\n",
        "    loss_train = []\n",
        "    loss_test = []\n",
        "    loss_val = []\n",
        "\n",
        "\n",
        "    for batch_i in range(0,int(num_batches)):\n",
        "      with tf.GradientTape() as tape:\n",
        "        x = x_train_new[batch_i*100:batch_i*100+100,:]\n",
        "        y = y_train[batch_i*100:batch_i*100+100,:]\n",
        "        x_tensor = K.constant(x)\n",
        "        y_tensor = K.constant(y)\n",
        "        predict_tensor = model(x_tensor,training=True)    # This runs the data through the model   F(x)\n",
        "        batch_log_loss = (-1/x_tensor.shape[0])*tf.math.reduce_sum(y_tensor * tf.math.log(tf.clip_by_value(predict_tensor,0.0000001,10.0)))\n",
        "        batch_log_loss_np = batch_log_loss.numpy()\n",
        "        loss_train.append(batch_log_loss_np)\n",
        "\n",
        "      grads = tape.gradient(batch_log_loss, model.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "      train_acc_metric.update_state(y_tensor, predict_tensor)\n",
        "\n",
        "    train_acc = train_acc_metric.result()\n",
        "    epoch_acc_train.append(train_acc)\n",
        "    print(\"Training acc over epoch: %.8f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "\n",
        "\n",
        "    for batch_i in range(0,10):\n",
        "      with tf.GradientTape() as tape:\n",
        "        x = x_val_new[batch_i*100:batch_i*100+100,:]\n",
        "        y = y_val[batch_i*100:batch_i*100+100,:]\n",
        "        x_tensor = K.constant(x)\n",
        "        y_tensor = K.constant(y)\n",
        "        predict_tensor = model(x_tensor, training=False)    # This runs the data through the model   F(x)\n",
        "        batch_log_loss = (-1/x_tensor.shape[0])*tf.math.reduce_sum(y_tensor * tf.math.log(tf.clip_by_value(predict_tensor,0.0000001,10.0)))\n",
        "        # loss_val = loss_val.append(batch_log_loss.numpy())\n",
        "        batch_log_loss_np = batch_log_loss.numpy()\n",
        "        loss_val.append(batch_log_loss_np)\n",
        "\n",
        "\n",
        "      grads = tape.gradient(batch_log_loss, model.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "      val_acc_metric.update_state(y_tensor, predict_tensor)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    epoch_acc_val.append(val_acc)\n",
        "    print(\"Validation acc over epoch: %.8f\" % (float(val_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    val_acc_metric.reset_states()\n",
        "\n",
        "\n",
        "    for batch_i in range(0,10):\n",
        "      with tf.GradientTape() as tape:\n",
        "        x = x_test_new[batch_i*100:batch_i*100+100,:]\n",
        "        y = y_test[batch_i*100:batch_i*100+100,:]\n",
        "        x_tensor = K.constant(x)\n",
        "        y_tensor = K.constant(y)\n",
        "        predict_tensor = model(x_tensor)    # This runs the data through the model   F(x) \n",
        "        batch_log_loss = (-1/x_tensor.shape[0])*tf.math.reduce_sum(y_tensor * tf.math.log(tf.clip_by_value(predict_tensor,0.0000001,10.0)))\n",
        "        # loss_test = loss_test.append(batch_log_loss.numpy())\n",
        "        batch_log_loss_np = batch_log_loss.numpy()\n",
        "        loss_test.append(batch_log_loss_np)\n",
        "\n",
        "\n",
        "      grads = tape.gradient(batch_log_loss, model.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "      test_acc_metric.update_state(y_tensor, predict_tensor)\n",
        "\n",
        "\n",
        "    test_acc = test_acc_metric.result()\n",
        "    epoch_acc_test.append(test_acc)\n",
        "    print(\"Test acc over epoch: %.8f\" % (float(test_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    test_acc_metric.reset_states()\n",
        "    \n",
        "    epoch_loss_train.append(np.mean(loss_train))\n",
        "    epoch_loss_test.append(np.mean(loss_test))\n",
        "    epoch_loss_val.append(np.mean(loss_val))\n",
        "    print(\"Train Loss: {}\".format(tf.reduce_mean(loss_train)))\n",
        "    print(\"Validation Loss: {}\".format(tf.reduce_mean(loss_val)))\n",
        "    print(\"Test Loss: {}\".format(tf.reduce_mean(loss_test)))\n",
        "    # if epoch_acc_val[-1] > val_acc_threshold:\n",
        "    #     print(\"Validation loss does not improved! early stopping\")\n",
        "    #     break\n",
        "\n",
        "\n",
        "# Now plot the loss and accuracy metrics\n",
        "\n",
        "training_loss = [i+1 for i in range(len(epoch_loss_train))]\n",
        "validation_loss = [i+1 for i in range(len(epoch_loss_val))]\n",
        "testing_loss = [i+1 for i in range(len(epoch_loss_test))]\n",
        "\n",
        "# print(len(epoch_loss_train))\n",
        "# print(len(epoch_loss_val))\n",
        "# print(len(epoch_loss_test))\n",
        "\n",
        "\n",
        "# Visualize loss history\n",
        "# print(len(training_loss), len(epoch_loss_train))\n",
        "plt.plot(training_loss, epoch_loss_train, 'r')\n",
        "plt.plot(training_loss, epoch_loss_val, 'b')\n",
        "plt.plot(training_loss, epoch_loss_test, 'g')\n",
        "plt.legend(['Training Loss', 'Validation Loss', 'Testing Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.savefig(\"output/loss.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize loss history\n",
        "# print(len(training_loss), len(epoch_acc_train))\n",
        "plt.plot(training_loss, epoch_acc_train, 'r')\n",
        "plt.plot(training_loss, epoch_acc_val,  'b')\n",
        "plt.plot(training_loss, epoch_acc_test, 'g')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy', 'Testing Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(\"output/accuracy.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F_1MSpb5ovhB",
        "outputId": "771dc67b-77fb-4d0c-a0eb-779b8a6663d3"
      },
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "****************** epoch - 1 ******************\n",
            "\n",
            "Training acc over epoch: 0.15099999\n",
            "Validation acc over epoch: 0.23899999\n",
            "Test acc over epoch: 0.25099999\n",
            "Train Loss: 3.155305862426758\n",
            "Validation Loss: 2.182443618774414\n",
            "Test Loss: 2.147869825363159\n",
            "\n",
            "\n",
            "****************** epoch - 2 ******************\n",
            "\n",
            "Training acc over epoch: 0.34150001\n",
            "Validation acc over epoch: 0.40400001\n",
            "Test acc over epoch: 0.37799999\n",
            "Train Loss: 1.9424514770507812\n",
            "Validation Loss: 1.7080084085464478\n",
            "Test Loss: 1.7207103967666626\n",
            "\n",
            "\n",
            "****************** epoch - 3 ******************\n",
            "\n",
            "Training acc over epoch: 0.46075001\n",
            "Validation acc over epoch: 0.51499999\n",
            "Test acc over epoch: 0.49700001\n",
            "Train Loss: 1.508156657218933\n",
            "Validation Loss: 1.368237018585205\n",
            "Test Loss: 1.4184798002243042\n",
            "\n",
            "\n",
            "****************** epoch - 4 ******************\n",
            "\n",
            "Training acc over epoch: 0.59224999\n",
            "Validation acc over epoch: 0.61699998\n",
            "Test acc over epoch: 0.60799998\n",
            "Train Loss: 1.1854530572891235\n",
            "Validation Loss: 1.1152193546295166\n",
            "Test Loss: 1.1367275714874268\n",
            "\n",
            "\n",
            "****************** epoch - 5 ******************\n",
            "\n",
            "Training acc over epoch: 0.68024999\n",
            "Validation acc over epoch: 0.71100003\n",
            "Test acc over epoch: 0.70800000\n",
            "Train Loss: 0.9493721723556519\n",
            "Validation Loss: 0.8658187985420227\n",
            "Test Loss: 0.8825753331184387\n",
            "\n",
            "\n",
            "****************** epoch - 6 ******************\n",
            "\n",
            "Training acc over epoch: 0.74800003\n",
            "Validation acc over epoch: 0.76200002\n",
            "Test acc over epoch: 0.76999998\n",
            "Train Loss: 0.7797107696533203\n",
            "Validation Loss: 0.7399834394454956\n",
            "Test Loss: 0.7452924847602844\n",
            "\n",
            "\n",
            "****************** epoch - 7 ******************\n",
            "\n",
            "Training acc over epoch: 0.78724998\n",
            "Validation acc over epoch: 0.81000000\n",
            "Test acc over epoch: 0.80100000\n",
            "Train Loss: 0.6542256474494934\n",
            "Validation Loss: 0.5976170301437378\n",
            "Test Loss: 0.6096522212028503\n",
            "\n",
            "\n",
            "****************** epoch - 8 ******************\n",
            "\n",
            "Training acc over epoch: 0.82599998\n",
            "Validation acc over epoch: 0.83099997\n",
            "Test acc over epoch: 0.82700002\n",
            "Train Loss: 0.5534789562225342\n",
            "Validation Loss: 0.5065258741378784\n",
            "Test Loss: 0.5393856763839722\n",
            "\n",
            "\n",
            "****************** epoch - 9 ******************\n",
            "\n",
            "Training acc over epoch: 0.85275000\n",
            "Validation acc over epoch: 0.86500001\n",
            "Test acc over epoch: 0.83999997\n",
            "Train Loss: 0.47425904870033264\n",
            "Validation Loss: 0.4468250274658203\n",
            "Test Loss: 0.4958842396736145\n",
            "\n",
            "\n",
            "****************** epoch - 10 ******************\n",
            "\n",
            "Training acc over epoch: 0.86549997\n",
            "Validation acc over epoch: 0.87800002\n",
            "Test acc over epoch: 0.84799999\n",
            "Train Loss: 0.43410730361938477\n",
            "Validation Loss: 0.4164859652519226\n",
            "Test Loss: 0.47090330719947815\n",
            "\n",
            "\n",
            "****************** epoch - 11 ******************\n",
            "\n",
            "Training acc over epoch: 0.87150002\n",
            "Validation acc over epoch: 0.88000000\n",
            "Test acc over epoch: 0.86900002\n",
            "Train Loss: 0.3941011428833008\n",
            "Validation Loss: 0.39376264810562134\n",
            "Test Loss: 0.4086441099643707\n",
            "\n",
            "\n",
            "****************** epoch - 12 ******************\n",
            "\n",
            "Training acc over epoch: 0.89150000\n",
            "Validation acc over epoch: 0.89999998\n",
            "Test acc over epoch: 0.88700002\n",
            "Train Loss: 0.3433511555194855\n",
            "Validation Loss: 0.3461967408657074\n",
            "Test Loss: 0.3645744323730469\n",
            "\n",
            "\n",
            "****************** epoch - 13 ******************\n",
            "\n",
            "Training acc over epoch: 0.89899999\n",
            "Validation acc over epoch: 0.91000003\n",
            "Test acc over epoch: 0.88499999\n",
            "Train Loss: 0.31852102279663086\n",
            "Validation Loss: 0.30904442071914673\n",
            "Test Loss: 0.3434354066848755\n",
            "\n",
            "\n",
            "****************** epoch - 14 ******************\n",
            "\n",
            "Training acc over epoch: 0.90649998\n",
            "Validation acc over epoch: 0.91100001\n",
            "Test acc over epoch: 0.89399999\n",
            "Train Loss: 0.29575514793395996\n",
            "Validation Loss: 0.2866232097148895\n",
            "Test Loss: 0.32895946502685547\n",
            "\n",
            "\n",
            "****************** epoch - 15 ******************\n",
            "\n",
            "Training acc over epoch: 0.92100000\n",
            "Validation acc over epoch: 0.91500002\n",
            "Test acc over epoch: 0.89700001\n",
            "Train Loss: 0.27038291096687317\n",
            "Validation Loss: 0.2654920220375061\n",
            "Test Loss: 0.31901389360427856\n",
            "\n",
            "\n",
            "****************** epoch - 16 ******************\n",
            "\n",
            "Training acc over epoch: 0.92075002\n",
            "Validation acc over epoch: 0.93099999\n",
            "Test acc over epoch: 0.90300000\n",
            "Train Loss: 0.25179457664489746\n",
            "Validation Loss: 0.2472284734249115\n",
            "Test Loss: 0.29246091842651367\n",
            "\n",
            "\n",
            "****************** epoch - 17 ******************\n",
            "\n",
            "Training acc over epoch: 0.92350000\n",
            "Validation acc over epoch: 0.92799997\n",
            "Test acc over epoch: 0.90399998\n",
            "Train Loss: 0.2461806833744049\n",
            "Validation Loss: 0.23902373015880585\n",
            "Test Loss: 0.27448520064353943\n",
            "\n",
            "\n",
            "****************** epoch - 18 ******************\n",
            "\n",
            "Training acc over epoch: 0.92925000\n",
            "Validation acc over epoch: 0.93400002\n",
            "Test acc over epoch: 0.91799998\n",
            "Train Loss: 0.22748307883739471\n",
            "Validation Loss: 0.22159221768379211\n",
            "Test Loss: 0.2553383409976959\n",
            "\n",
            "\n",
            "****************** epoch - 19 ******************\n",
            "\n",
            "Training acc over epoch: 0.93575001\n",
            "Validation acc over epoch: 0.93800002\n",
            "Test acc over epoch: 0.92100000\n",
            "Train Loss: 0.20772461593151093\n",
            "Validation Loss: 0.21256181597709656\n",
            "Test Loss: 0.24830886721611023\n",
            "\n",
            "\n",
            "****************** epoch - 20 ******************\n",
            "\n",
            "Training acc over epoch: 0.93325001\n",
            "Validation acc over epoch: 0.93800002\n",
            "Test acc over epoch: 0.92600000\n",
            "Train Loss: 0.20159947872161865\n",
            "Validation Loss: 0.20012322068214417\n",
            "Test Loss: 0.24137091636657715\n",
            "\n",
            "\n",
            "****************** epoch - 21 ******************\n",
            "\n",
            "Training acc over epoch: 0.94174999\n",
            "Validation acc over epoch: 0.94000000\n",
            "Test acc over epoch: 0.92600000\n",
            "Train Loss: 0.18760699033737183\n",
            "Validation Loss: 0.19476218521595\n",
            "Test Loss: 0.23916184902191162\n",
            "\n",
            "\n",
            "****************** epoch - 22 ******************\n",
            "\n",
            "Training acc over epoch: 0.94225001\n",
            "Validation acc over epoch: 0.94300002\n",
            "Test acc over epoch: 0.92400002\n",
            "Train Loss: 0.18172545731067657\n",
            "Validation Loss: 0.1883329600095749\n",
            "Test Loss: 0.2392309159040451\n",
            "\n",
            "\n",
            "****************** epoch - 23 ******************\n",
            "\n",
            "Training acc over epoch: 0.94375002\n",
            "Validation acc over epoch: 0.94599998\n",
            "Test acc over epoch: 0.92900002\n",
            "Train Loss: 0.1758306473493576\n",
            "Validation Loss: 0.17294830083847046\n",
            "Test Loss: 0.21605804562568665\n",
            "\n",
            "\n",
            "****************** epoch - 24 ******************\n",
            "\n",
            "Training acc over epoch: 0.94625002\n",
            "Validation acc over epoch: 0.94400001\n",
            "Test acc over epoch: 0.93400002\n",
            "Train Loss: 0.1708298623561859\n",
            "Validation Loss: 0.17384183406829834\n",
            "Test Loss: 0.20752879977226257\n",
            "\n",
            "\n",
            "****************** epoch - 25 ******************\n",
            "\n",
            "Training acc over epoch: 0.94625002\n",
            "Validation acc over epoch: 0.94800001\n",
            "Test acc over epoch: 0.94400001\n",
            "Train Loss: 0.16817116737365723\n",
            "Validation Loss: 0.16537579894065857\n",
            "Test Loss: 0.1849825531244278\n",
            "\n",
            "\n",
            "****************** epoch - 26 ******************\n",
            "\n",
            "Training acc over epoch: 0.94599998\n",
            "Validation acc over epoch: 0.94900000\n",
            "Test acc over epoch: 0.94400001\n",
            "Train Loss: 0.16677816212177277\n",
            "Validation Loss: 0.15891869366168976\n",
            "Test Loss: 0.1823766529560089\n",
            "\n",
            "\n",
            "****************** epoch - 27 ******************\n",
            "\n",
            "Training acc over epoch: 0.94400001\n",
            "Validation acc over epoch: 0.94000000\n",
            "Test acc over epoch: 0.93400002\n",
            "Train Loss: 0.1803116798400879\n",
            "Validation Loss: 0.18986408412456512\n",
            "Test Loss: 0.19925685226917267\n",
            "\n",
            "\n",
            "****************** epoch - 28 ******************\n",
            "\n",
            "Training acc over epoch: 0.94199997\n",
            "Validation acc over epoch: 0.93699998\n",
            "Test acc over epoch: 0.94400001\n",
            "Train Loss: 0.17779944837093353\n",
            "Validation Loss: 0.203642338514328\n",
            "Test Loss: 0.1986907422542572\n",
            "\n",
            "\n",
            "****************** epoch - 29 ******************\n",
            "\n",
            "Training acc over epoch: 0.93575001\n",
            "Validation acc over epoch: 0.94000000\n",
            "Test acc over epoch: 0.93199998\n",
            "Train Loss: 0.18998460471630096\n",
            "Validation Loss: 0.18127457797527313\n",
            "Test Loss: 0.2081001251935959\n",
            "\n",
            "\n",
            "****************** epoch - 30 ******************\n",
            "\n",
            "Training acc over epoch: 0.93624997\n",
            "Validation acc over epoch: 0.94000000\n",
            "Test acc over epoch: 0.94400001\n",
            "Train Loss: 0.19445638358592987\n",
            "Validation Loss: 0.19384285807609558\n",
            "Test Loss: 0.1838732659816742\n",
            "\n",
            "\n",
            "****************** epoch - 31 ******************\n",
            "\n",
            "Training acc over epoch: 0.94475001\n",
            "Validation acc over epoch: 0.94999999\n",
            "Test acc over epoch: 0.94000000\n",
            "Train Loss: 0.16927167773246765\n",
            "Validation Loss: 0.13720400631427765\n",
            "Test Loss: 0.17906177043914795\n",
            "\n",
            "\n",
            "****************** epoch - 32 ******************\n",
            "\n",
            "Training acc over epoch: 0.94924998\n",
            "Validation acc over epoch: 0.96300000\n",
            "Test acc over epoch: 0.94300002\n",
            "Train Loss: 0.15373119711875916\n",
            "Validation Loss: 0.12572363018989563\n",
            "Test Loss: 0.1655675172805786\n",
            "\n",
            "\n",
            "****************** epoch - 33 ******************\n",
            "\n",
            "Training acc over epoch: 0.95499998\n",
            "Validation acc over epoch: 0.95800000\n",
            "Test acc over epoch: 0.94000000\n",
            "Train Loss: 0.1370144933462143\n",
            "Validation Loss: 0.1240391731262207\n",
            "Test Loss: 0.17127102613449097\n",
            "\n",
            "\n",
            "****************** epoch - 34 ******************\n",
            "\n",
            "Training acc over epoch: 0.95975000\n",
            "Validation acc over epoch: 0.96300000\n",
            "Test acc over epoch: 0.94700003\n",
            "Train Loss: 0.12936480343341827\n",
            "Validation Loss: 0.11931024491786957\n",
            "Test Loss: 0.16971777379512787\n",
            "\n",
            "\n",
            "****************** epoch - 35 ******************\n",
            "\n",
            "Training acc over epoch: 0.95599997\n",
            "Validation acc over epoch: 0.96899998\n",
            "Test acc over epoch: 0.95200002\n",
            "Train Loss: 0.1329670250415802\n",
            "Validation Loss: 0.10885725915431976\n",
            "Test Loss: 0.14923299849033356\n",
            "\n",
            "\n",
            "****************** epoch - 36 ******************\n",
            "\n",
            "Training acc over epoch: 0.95099998\n",
            "Validation acc over epoch: 0.97299999\n",
            "Test acc over epoch: 0.95599997\n",
            "Train Loss: 0.13716283440589905\n",
            "Validation Loss: 0.10230721533298492\n",
            "Test Loss: 0.13349004089832306\n",
            "\n",
            "\n",
            "****************** epoch - 37 ******************\n",
            "\n",
            "Training acc over epoch: 0.96074998\n",
            "Validation acc over epoch: 0.96100003\n",
            "Test acc over epoch: 0.95599997\n",
            "Train Loss: 0.12568138539791107\n",
            "Validation Loss: 0.11931810528039932\n",
            "Test Loss: 0.1288144588470459\n",
            "\n",
            "\n",
            "****************** epoch - 38 ******************\n",
            "\n",
            "Training acc over epoch: 0.96100003\n",
            "Validation acc over epoch: 0.95499998\n",
            "Test acc over epoch: 0.95300001\n",
            "Train Loss: 0.11636972427368164\n",
            "Validation Loss: 0.12238864600658417\n",
            "Test Loss: 0.1439252495765686\n",
            "\n",
            "\n",
            "****************** epoch - 39 ******************\n",
            "\n",
            "Training acc over epoch: 0.96675003\n",
            "Validation acc over epoch: 0.96300000\n",
            "Test acc over epoch: 0.94999999\n",
            "Train Loss: 0.10327453911304474\n",
            "Validation Loss: 0.11472710222005844\n",
            "Test Loss: 0.14784613251686096\n",
            "\n",
            "\n",
            "****************** epoch - 40 ******************\n",
            "\n",
            "Training acc over epoch: 0.96775001\n",
            "Validation acc over epoch: 0.96300000\n",
            "Test acc over epoch: 0.96100003\n",
            "Train Loss: 0.09878432750701904\n",
            "Validation Loss: 0.1046319454908371\n",
            "Test Loss: 0.13795946538448334\n",
            "\n",
            "\n",
            "****************** epoch - 41 ******************\n",
            "\n",
            "Training acc over epoch: 0.96675003\n",
            "Validation acc over epoch: 0.96899998\n",
            "Test acc over epoch: 0.96399999\n",
            "Train Loss: 0.09968437999486923\n",
            "Validation Loss: 0.09000378847122192\n",
            "Test Loss: 0.12827572226524353\n",
            "\n",
            "\n",
            "****************** epoch - 42 ******************\n",
            "\n",
            "Training acc over epoch: 0.96550000\n",
            "Validation acc over epoch: 0.96600002\n",
            "Test acc over epoch: 0.96499997\n",
            "Train Loss: 0.10019852966070175\n",
            "Validation Loss: 0.10192468017339706\n",
            "Test Loss: 0.12681785225868225\n",
            "\n",
            "\n",
            "****************** epoch - 43 ******************\n",
            "\n",
            "Training acc over epoch: 0.96574998\n",
            "Validation acc over epoch: 0.96899998\n",
            "Test acc over epoch: 0.96200001\n",
            "Train Loss: 0.09630467742681503\n",
            "Validation Loss: 0.09363330900669098\n",
            "Test Loss: 0.11378228664398193\n",
            "\n",
            "\n",
            "****************** epoch - 44 ******************\n",
            "\n",
            "Training acc over epoch: 0.96850002\n",
            "Validation acc over epoch: 0.97899997\n",
            "Test acc over epoch: 0.96100003\n",
            "Train Loss: 0.09649641066789627\n",
            "Validation Loss: 0.07804490625858307\n",
            "Test Loss: 0.1022263765335083\n",
            "\n",
            "\n",
            "****************** epoch - 45 ******************\n",
            "\n",
            "Training acc over epoch: 0.97425002\n",
            "Validation acc over epoch: 0.97299999\n",
            "Test acc over epoch: 0.95999998\n",
            "Train Loss: 0.07852563261985779\n",
            "Validation Loss: 0.07673671096563339\n",
            "Test Loss: 0.10488863289356232\n",
            "\n",
            "\n",
            "****************** epoch - 46 ******************\n",
            "\n",
            "Training acc over epoch: 0.97275001\n",
            "Validation acc over epoch: 0.97799999\n",
            "Test acc over epoch: 0.96799999\n",
            "Train Loss: 0.07582396268844604\n",
            "Validation Loss: 0.0707525908946991\n",
            "Test Loss: 0.09034977853298187\n",
            "\n",
            "\n",
            "****************** epoch - 47 ******************\n",
            "\n",
            "Training acc over epoch: 0.97000003\n",
            "Validation acc over epoch: 0.97200000\n",
            "Test acc over epoch: 0.96799999\n",
            "Train Loss: 0.0894208550453186\n",
            "Validation Loss: 0.0750773698091507\n",
            "Test Loss: 0.08108379691839218\n",
            "\n",
            "\n",
            "****************** epoch - 48 ******************\n",
            "\n",
            "Training acc over epoch: 0.97600001\n",
            "Validation acc over epoch: 0.98000002\n",
            "Test acc over epoch: 0.97299999\n",
            "Train Loss: 0.07467074692249298\n",
            "Validation Loss: 0.06391477584838867\n",
            "Test Loss: 0.08544571697711945\n",
            "\n",
            "\n",
            "****************** epoch - 49 ******************\n",
            "\n",
            "Training acc over epoch: 0.97874999\n",
            "Validation acc over epoch: 0.97200000\n",
            "Test acc over epoch: 0.96799999\n",
            "Train Loss: 0.06308092921972275\n",
            "Validation Loss: 0.07084287703037262\n",
            "Test Loss: 0.09000243991613388\n",
            "\n",
            "\n",
            "****************** epoch - 50 ******************\n",
            "\n",
            "Training acc over epoch: 0.97974998\n",
            "Validation acc over epoch: 0.96600002\n",
            "Test acc over epoch: 0.95400000\n",
            "Train Loss: 0.058276571333408356\n",
            "Validation Loss: 0.09447195380926132\n",
            "Test Loss: 0.14499028027057648\n",
            "\n",
            "\n",
            "****************** epoch - 51 ******************\n",
            "\n",
            "Training acc over epoch: 0.98025000\n",
            "Validation acc over epoch: 0.97500002\n",
            "Test acc over epoch: 0.93599999\n",
            "Train Loss: 0.05580407381057739\n",
            "Validation Loss: 0.07508702576160431\n",
            "Test Loss: 0.19405986368656158\n",
            "\n",
            "\n",
            "****************** epoch - 52 ******************\n",
            "\n",
            "Training acc over epoch: 0.97624999\n",
            "Validation acc over epoch: 0.97500002\n",
            "Test acc over epoch: 0.96200001\n",
            "Train Loss: 0.06762712448835373\n",
            "Validation Loss: 0.060451190918684006\n",
            "Test Loss: 0.09134109318256378\n",
            "\n",
            "\n",
            "****************** epoch - 53 ******************\n",
            "\n",
            "Training acc over epoch: 0.96799999\n",
            "Validation acc over epoch: 0.98199999\n",
            "Test acc over epoch: 0.97700000\n",
            "Train Loss: 0.09125857055187225\n",
            "Validation Loss: 0.051884304732084274\n",
            "Test Loss: 0.0664089098572731\n",
            "\n",
            "\n",
            "****************** epoch - 54 ******************\n",
            "\n",
            "Training acc over epoch: 0.98124999\n",
            "Validation acc over epoch: 0.97799999\n",
            "Test acc over epoch: 0.97000003\n",
            "Train Loss: 0.05359038710594177\n",
            "Validation Loss: 0.06402936577796936\n",
            "Test Loss: 0.07422789186239243\n",
            "\n",
            "\n",
            "****************** epoch - 55 ******************\n",
            "\n",
            "Training acc over epoch: 0.97700000\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.97899997\n",
            "Train Loss: 0.06329189240932465\n",
            "Validation Loss: 0.05139509588479996\n",
            "Test Loss: 0.06254364550113678\n",
            "\n",
            "\n",
            "****************** epoch - 56 ******************\n",
            "\n",
            "Training acc over epoch: 0.98049998\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.97799999\n",
            "Train Loss: 0.054469186812639236\n",
            "Validation Loss: 0.04842124134302139\n",
            "Test Loss: 0.06754569709300995\n",
            "\n",
            "\n",
            "****************** epoch - 57 ******************\n",
            "\n",
            "Training acc over epoch: 0.97675002\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.98900002\n",
            "Train Loss: 0.06189688295125961\n",
            "Validation Loss: 0.05129467323422432\n",
            "Test Loss: 0.04323364049196243\n",
            "\n",
            "\n",
            "****************** epoch - 58 ******************\n",
            "\n",
            "Training acc over epoch: 0.98575002\n",
            "Validation acc over epoch: 0.99000001\n",
            "Test acc over epoch: 0.99100000\n",
            "Train Loss: 0.03980422019958496\n",
            "Validation Loss: 0.034508246928453445\n",
            "Test Loss: 0.03304082900285721\n",
            "\n",
            "\n",
            "****************** epoch - 59 ******************\n",
            "\n",
            "Training acc over epoch: 0.98549998\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.03741459921002388\n",
            "Validation Loss: 0.05095229297876358\n",
            "Test Loss: 0.03997782617807388\n",
            "\n",
            "\n",
            "****************** epoch - 60 ******************\n",
            "\n",
            "Training acc over epoch: 0.98799998\n",
            "Validation acc over epoch: 0.99000001\n",
            "Test acc over epoch: 0.98500001\n",
            "Train Loss: 0.03389295935630798\n",
            "Validation Loss: 0.03909527510404587\n",
            "Test Loss: 0.03733990341424942\n",
            "\n",
            "\n",
            "****************** epoch - 61 ******************\n",
            "\n",
            "Training acc over epoch: 0.98724997\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.98500001\n",
            "Train Loss: 0.037736453115940094\n",
            "Validation Loss: 0.04944584518671036\n",
            "Test Loss: 0.04561518877744675\n",
            "\n",
            "\n",
            "****************** epoch - 62 ******************\n",
            "\n",
            "Training acc over epoch: 0.98525000\n",
            "Validation acc over epoch: 0.98600000\n",
            "Test acc over epoch: 0.98100001\n",
            "Train Loss: 0.04280700534582138\n",
            "Validation Loss: 0.04603137820959091\n",
            "Test Loss: 0.049131136387586594\n",
            "\n",
            "\n",
            "****************** epoch - 63 ******************\n",
            "\n",
            "Training acc over epoch: 0.98400003\n",
            "Validation acc over epoch: 0.95899999\n",
            "Test acc over epoch: 0.96300000\n",
            "Train Loss: 0.04576699808239937\n",
            "Validation Loss: 0.11082631349563599\n",
            "Test Loss: 0.12251957505941391\n",
            "\n",
            "\n",
            "****************** epoch - 64 ******************\n",
            "\n",
            "Training acc over epoch: 0.98275000\n",
            "Validation acc over epoch: 0.98900002\n",
            "Test acc over epoch: 0.97899997\n",
            "Train Loss: 0.04720519855618477\n",
            "Validation Loss: 0.03583784028887749\n",
            "Test Loss: 0.05404927581548691\n",
            "\n",
            "\n",
            "****************** epoch - 65 ******************\n",
            "\n",
            "Training acc over epoch: 0.99250001\n",
            "Validation acc over epoch: 0.99299997\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.026516998186707497\n",
            "Validation Loss: 0.022433271631598473\n",
            "Test Loss: 0.034135136753320694\n",
            "\n",
            "\n",
            "****************** epoch - 66 ******************\n",
            "\n",
            "Training acc over epoch: 0.99000001\n",
            "Validation acc over epoch: 0.98699999\n",
            "Test acc over epoch: 0.99100000\n",
            "Train Loss: 0.029115483164787292\n",
            "Validation Loss: 0.03779192641377449\n",
            "Test Loss: 0.029058147221803665\n",
            "\n",
            "\n",
            "****************** epoch - 67 ******************\n",
            "\n",
            "Training acc over epoch: 0.98575002\n",
            "Validation acc over epoch: 0.98600000\n",
            "Test acc over epoch: 0.97899997\n",
            "Train Loss: 0.04058730974793434\n",
            "Validation Loss: 0.04827744513750076\n",
            "Test Loss: 0.060443658381700516\n",
            "\n",
            "\n",
            "****************** epoch - 68 ******************\n",
            "\n",
            "Training acc over epoch: 0.98750001\n",
            "Validation acc over epoch: 0.98000002\n",
            "Test acc over epoch: 0.97899997\n",
            "Train Loss: 0.035225920379161835\n",
            "Validation Loss: 0.052460528910160065\n",
            "Test Loss: 0.05377688258886337\n",
            "\n",
            "\n",
            "****************** epoch - 69 ******************\n",
            "\n",
            "Training acc over epoch: 0.98650002\n",
            "Validation acc over epoch: 0.99100000\n",
            "Test acc over epoch: 0.98100001\n",
            "Train Loss: 0.03589789196848869\n",
            "Validation Loss: 0.03202047199010849\n",
            "Test Loss: 0.051449041813611984\n",
            "\n",
            "\n",
            "****************** epoch - 70 ******************\n",
            "\n",
            "Training acc over epoch: 0.98774999\n",
            "Validation acc over epoch: 0.98600000\n",
            "Test acc over epoch: 0.98199999\n",
            "Train Loss: 0.03481294959783554\n",
            "Validation Loss: 0.0352892130613327\n",
            "Test Loss: 0.05369795486330986\n",
            "\n",
            "\n",
            "****************** epoch - 71 ******************\n",
            "\n",
            "Training acc over epoch: 0.98949999\n",
            "Validation acc over epoch: 0.99199998\n",
            "Test acc over epoch: 0.98900002\n",
            "Train Loss: 0.032157350331544876\n",
            "Validation Loss: 0.021447908133268356\n",
            "Test Loss: 0.0293679591268301\n",
            "\n",
            "\n",
            "****************** epoch - 72 ******************\n",
            "\n",
            "Training acc over epoch: 0.99199998\n",
            "Validation acc over epoch: 0.99500000\n",
            "Test acc over epoch: 0.99100000\n",
            "Train Loss: 0.022600224241614342\n",
            "Validation Loss: 0.019300660118460655\n",
            "Test Loss: 0.028663303703069687\n",
            "\n",
            "\n",
            "****************** epoch - 73 ******************\n",
            "\n",
            "Training acc over epoch: 0.99325001\n",
            "Validation acc over epoch: 0.99100000\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.020208459347486496\n",
            "Validation Loss: 0.02540932595729828\n",
            "Test Loss: 0.03636696934700012\n",
            "\n",
            "\n",
            "****************** epoch - 74 ******************\n",
            "\n",
            "Training acc over epoch: 0.98949999\n",
            "Validation acc over epoch: 0.99000001\n",
            "Test acc over epoch: 0.99199998\n",
            "Train Loss: 0.027647212147712708\n",
            "Validation Loss: 0.03459819406270981\n",
            "Test Loss: 0.03280502185225487\n",
            "\n",
            "\n",
            "****************** epoch - 75 ******************\n",
            "\n",
            "Training acc over epoch: 0.99075001\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.96899998\n",
            "Train Loss: 0.025590181350708008\n",
            "Validation Loss: 0.0564580038189888\n",
            "Test Loss: 0.08005901426076889\n",
            "\n",
            "\n",
            "****************** epoch - 76 ******************\n",
            "\n",
            "Training acc over epoch: 0.98799998\n",
            "Validation acc over epoch: 0.99199998\n",
            "Test acc over epoch: 0.98600000\n",
            "Train Loss: 0.03209581971168518\n",
            "Validation Loss: 0.0214802585542202\n",
            "Test Loss: 0.04689779505133629\n",
            "\n",
            "\n",
            "****************** epoch - 77 ******************\n",
            "\n",
            "Training acc over epoch: 0.98900002\n",
            "Validation acc over epoch: 0.98199999\n",
            "Test acc over epoch: 0.98600000\n",
            "Train Loss: 0.029290471225976944\n",
            "Validation Loss: 0.04506976529955864\n",
            "Test Loss: 0.043403226882219315\n",
            "\n",
            "\n",
            "****************** epoch - 78 ******************\n",
            "\n",
            "Training acc over epoch: 0.99374998\n",
            "Validation acc over epoch: 0.98500001\n",
            "Test acc over epoch: 0.98100001\n",
            "Train Loss: 0.019029295071959496\n",
            "Validation Loss: 0.038807906210422516\n",
            "Test Loss: 0.049764711409807205\n",
            "\n",
            "\n",
            "****************** epoch - 79 ******************\n",
            "\n",
            "Training acc over epoch: 0.98350000\n",
            "Validation acc over epoch: 0.98699999\n",
            "Test acc over epoch: 0.98900002\n",
            "Train Loss: 0.04979240149259567\n",
            "Validation Loss: 0.03919554874300957\n",
            "Test Loss: 0.025339758023619652\n",
            "\n",
            "\n",
            "****************** epoch - 80 ******************\n",
            "\n",
            "Training acc over epoch: 0.98900002\n",
            "Validation acc over epoch: 0.99199998\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.028511028736829758\n",
            "Validation Loss: 0.022552374750375748\n",
            "Test Loss: 0.03675549104809761\n",
            "\n",
            "\n",
            "****************** epoch - 81 ******************\n",
            "\n",
            "Training acc over epoch: 0.98224998\n",
            "Validation acc over epoch: 0.97600001\n",
            "Test acc over epoch: 0.98500001\n",
            "Train Loss: 0.047073908150196075\n",
            "Validation Loss: 0.071058489382267\n",
            "Test Loss: 0.03350882977247238\n",
            "\n",
            "\n",
            "****************** epoch - 82 ******************\n",
            "\n",
            "Training acc over epoch: 0.99000001\n",
            "Validation acc over epoch: 0.99299997\n",
            "Test acc over epoch: 0.99100000\n",
            "Train Loss: 0.030773360282182693\n",
            "Validation Loss: 0.019950183108448982\n",
            "Test Loss: 0.029191534966230392\n",
            "\n",
            "\n",
            "****************** epoch - 83 ******************\n",
            "\n",
            "Training acc over epoch: 0.99000001\n",
            "Validation acc over epoch: 0.99599999\n",
            "Test acc over epoch: 0.98699999\n",
            "Train Loss: 0.0336109958589077\n",
            "Validation Loss: 0.014474054798483849\n",
            "Test Loss: 0.03322552144527435\n",
            "\n",
            "\n",
            "****************** epoch - 84 ******************\n",
            "\n",
            "Training acc over epoch: 0.98500001\n",
            "Validation acc over epoch: 0.99100000\n",
            "Test acc over epoch: 0.98699999\n",
            "Train Loss: 0.04672830179333687\n",
            "Validation Loss: 0.03070247732102871\n",
            "Test Loss: 0.044703125953674316\n",
            "\n",
            "\n",
            "****************** epoch - 85 ******************\n",
            "\n",
            "Training acc over epoch: 0.98549998\n",
            "Validation acc over epoch: 0.99400002\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.049096979200839996\n",
            "Validation Loss: 0.018470821902155876\n",
            "Test Loss: 0.03102393075823784\n",
            "\n",
            "\n",
            "****************** epoch - 86 ******************\n",
            "\n",
            "Training acc over epoch: 0.98549998\n",
            "Validation acc over epoch: 0.99299997\n",
            "Test acc over epoch: 0.99199998\n",
            "Train Loss: 0.03982054442167282\n",
            "Validation Loss: 0.02227245271205902\n",
            "Test Loss: 0.026831289753317833\n",
            "\n",
            "\n",
            "****************** epoch - 87 ******************\n",
            "\n",
            "Training acc over epoch: 0.98624998\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.97000003\n",
            "Train Loss: 0.03739433363080025\n",
            "Validation Loss: 0.06353043019771576\n",
            "Test Loss: 0.09593872725963593\n",
            "\n",
            "\n",
            "****************** epoch - 88 ******************\n",
            "\n",
            "Training acc over epoch: 0.98325002\n",
            "Validation acc over epoch: 0.98799998\n",
            "Test acc over epoch: 0.98400003\n",
            "Train Loss: 0.054614823311567307\n",
            "Validation Loss: 0.03865686431527138\n",
            "Test Loss: 0.047218237072229385\n",
            "\n",
            "\n",
            "****************** epoch - 89 ******************\n",
            "\n",
            "Training acc over epoch: 0.98500001\n",
            "Validation acc over epoch: 0.98699999\n",
            "Test acc over epoch: 0.97799999\n",
            "Train Loss: 0.04200911521911621\n",
            "Validation Loss: 0.029770374298095703\n",
            "Test Loss: 0.05815780162811279\n",
            "\n",
            "\n",
            "****************** epoch - 90 ******************\n",
            "\n",
            "Training acc over epoch: 0.98799998\n",
            "Validation acc over epoch: 0.99500000\n",
            "Test acc over epoch: 0.99599999\n",
            "Train Loss: 0.03271660953760147\n",
            "Validation Loss: 0.018794024363160133\n",
            "Test Loss: 0.018707657232880592\n",
            "\n",
            "\n",
            "****************** epoch - 91 ******************\n",
            "\n",
            "Training acc over epoch: 0.99075001\n",
            "Validation acc over epoch: 0.98900002\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.029657745733857155\n",
            "Validation Loss: 0.03545450419187546\n",
            "Test Loss: 0.028084615245461464\n",
            "\n",
            "\n",
            "****************** epoch - 92 ******************\n",
            "\n",
            "Training acc over epoch: 0.97950000\n",
            "Validation acc over epoch: 0.98299998\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.057856567203998566\n",
            "Validation Loss: 0.04018652066588402\n",
            "Test Loss: 0.03311906382441521\n",
            "\n",
            "\n",
            "****************** epoch - 93 ******************\n",
            "\n",
            "Training acc over epoch: 0.98975003\n",
            "Validation acc over epoch: 0.98500001\n",
            "Test acc over epoch: 0.98799998\n",
            "Train Loss: 0.028306791558861732\n",
            "Validation Loss: 0.04188910126686096\n",
            "Test Loss: 0.03361364081501961\n",
            "\n",
            "\n",
            "****************** epoch - 94 ******************\n",
            "\n",
            "Training acc over epoch: 0.99049997\n",
            "Validation acc over epoch: 0.98699999\n",
            "Test acc over epoch: 0.98600000\n",
            "Train Loss: 0.028231078758835793\n",
            "Validation Loss: 0.038245879113674164\n",
            "Test Loss: 0.045315708965063095\n",
            "\n",
            "\n",
            "****************** epoch - 95 ******************\n",
            "\n",
            "Training acc over epoch: 0.98525000\n",
            "Validation acc over epoch: 0.99400002\n",
            "Test acc over epoch: 0.99100000\n",
            "Train Loss: 0.04199107736349106\n",
            "Validation Loss: 0.020704321563243866\n",
            "Test Loss: 0.028053995221853256\n",
            "\n",
            "\n",
            "****************** epoch - 96 ******************\n",
            "\n",
            "Training acc over epoch: 0.98400003\n",
            "Validation acc over epoch: 0.98000002\n",
            "Test acc over epoch: 0.98100001\n",
            "Train Loss: 0.04902275651693344\n",
            "Validation Loss: 0.07166354358196259\n",
            "Test Loss: 0.051128845661878586\n",
            "\n",
            "\n",
            "****************** epoch - 97 ******************\n",
            "\n",
            "Training acc over epoch: 0.99374998\n",
            "Validation acc over epoch: 0.99100000\n",
            "Test acc over epoch: 0.98500001\n",
            "Train Loss: 0.022387366741895676\n",
            "Validation Loss: 0.03678681701421738\n",
            "Test Loss: 0.04551909118890762\n",
            "\n",
            "\n",
            "****************** epoch - 98 ******************\n",
            "\n",
            "Training acc over epoch: 0.99175000\n",
            "Validation acc over epoch: 0.99100000\n",
            "Test acc over epoch: 0.99400002\n",
            "Train Loss: 0.019390176981687546\n",
            "Validation Loss: 0.02802368625998497\n",
            "Test Loss: 0.01737956702709198\n",
            "\n",
            "\n",
            "****************** epoch - 99 ******************\n",
            "\n",
            "Training acc over epoch: 0.99000001\n",
            "Validation acc over epoch: 0.99400002\n",
            "Test acc over epoch: 0.98699999\n",
            "Train Loss: 0.02536950446665287\n",
            "Validation Loss: 0.02784930169582367\n",
            "Test Loss: 0.040167950093746185\n",
            "\n",
            "\n",
            "****************** epoch - 100 ******************\n",
            "\n",
            "Training acc over epoch: 0.99049997\n",
            "Validation acc over epoch: 0.98600000\n",
            "Test acc over epoch: 0.99000001\n",
            "Train Loss: 0.023954886943101883\n",
            "Validation Loss: 0.03315176069736481\n",
            "Test Loss: 0.02589055895805359\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1OF_t2uASskd"
      },
      "execution_count": 610,
      "outputs": []
    }
  ]
}